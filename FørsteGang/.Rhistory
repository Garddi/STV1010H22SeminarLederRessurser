column.labels = c("biased unconditional",
"biased",
"unbiased conditional"))
lm4 <- lm(wage ~ femal + occupation + education, tb)
lm4 <- lm(wage ~ female + occupation + education, tb)
summary(lm4)
stargazer(lm1, lm2, lm3, lm4, type = "text",
column.labels = c("biased unconditional",
"biased",
"unbiased conditional",
"My Own"))
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
library(tidyverse)
library(rethinking)
p_grid <- seq(from = 0, to = 1, length.out = 100)
likelihood <- dbinom(3, size = 3, prob=p_grid)
prior <- rep(1,100)
posterior <- prior*likelihood
posterior <- posterior/sum(posterior)
plot(posterior)
plot(posterior ~ p_grid)
plot(posterior ~ p_grid, type="l")
p_grid <- seq(from = 0, to = 1, length.out = 100)
likelihood <- dbinom(3, size = 4, prob=p_grid)
prior <- rep(1,100)
posterior <- prior*likelihood
posterior <- posterior/sum(posterior)
plot(posterior ~ p_grid, type="l")
p_grid <- seq(from = 0, to = 1, length.out = 100)
likelihood <- dbinom(5, size = 7, prob=p_grid)
prior <- rep(1,100)
posterior <- prior*likelihood
posterior <- posterior/sum(posterior)
plot(posterior ~ p_grid, type="l")
p_grid <- seq(from = 0, to = 1, length.out = 100)
likelihood <- dbinom(3, size = 3, prob=p_grid)
prior <- ifelse(p_grid < 0.5, 0, 1)
posterior <- prior*likelihood
posterior <- posterior/sum(posterior)
plot(posterior ~ p_grid, type="l")
p_grid <- seq(from = 0, to = 1, length.out = 100)
likelihood <- dbinom(3, size = 4, prob=p_grid)
prior <- ifelse(p_grid < 0.5, 0, 1)
posterior <- prior*likelihood
posterior <- posterior/sum(posterior)
plot(posterior ~ p_grid, type="l")
likelihood <- dbinom(5, size = 7, prob=p_grid)
prior <- ifelse(p_grid < 0.5, 0, 1)
posterior <- prior*likelihood
posterior <- posterior/sum(posterior)
plot(posterior ~ p_grid, type="l")
rm(list = ls())
p_grid <- seq(from = 0, to = 1, length.out = 1000)
prior <- rep(1, 1000)
likelhood <- dbinom(6, size = 9, prob = p_grid)
posterior <- likelihood*prior
likelihood <- dbinom(6, size = 9, prob = p_grid)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
set.seed(100)
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
table(samples < 0.2)
sum(samples < 0.2)
sum(samples > 0.8)
sum(samples < 0.2)/1e4
sum(samples > 0.8)/1e4
sum(samples > 0.2 & samples < 0.8)/1e4
quantile(samples, 0.2)
sum(samples < 0.5185185)
sum(samples < 0.5185185)/1e4
sum(samples < 0.51852)/1e4
quantile(samples, 0.8)
sum(samples > 0.76)/1e4
HPDI(samples, prob=0.66)
PI(samples, prob = 0.66)
likelihood <- dbinom(8, size = 15, prob = p_grid)
posterior <- likelihood*priod
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
plot(posterior)
plot(posterior ~ p_grid, type = "l")
samples <- sample(p_grid, prob=posterior, size = 1e4, replace = TRUE)
HPDI(samples, prob=0.9)
w <- rbinom(1e4, size = 15, prob=samples)
sum(w == 8)/1e4
w2 <- rbinom(1e4, size = 9, prob=samples)
sum(w2 == 6)/1e4
simplehist(w)
prior <- ifelse(p_grid < 0.5, 0, 1)
likelihood <- dbinom(8, size = 15, prob = p_grid)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
samples <- sample(p_grid, prob=posterior, size = 1e4, replace = TRUE)
w <- rbinom(1e4, size = 15, prob = samples)
sum(w == 8)/1e4
w2 <- rbinom(1e4, size = 9, prob=samples)
sum(w2 == 8)/1e4
plot(posterior ~ p_grid, type = "l")
data(homeworkch4)
data(homeworkch3)
sum(birth1) + sum(birth2)
p <- seq(from = 1, to = 100, length.out = 1000)
prior <- rep(1, length(p))
likelihood <- dbinom(boys, size = 200, prob=p)
boys <- sum(birth1) + sum(birth2)
likelihood <- dbinom(boys, size = 200, prob=p)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
plot(posterior ~ p, type = "l")
boys <- sum(birth1) + sum(birth2)
p <- seq(from = 1, to = 100, length.out = 1000)
prior <- rep(1, length(p))
likelihood <- dbinom(boys, size = 200, prob=p)
p[which.max(posterior)]
likelihood <- dbinom(111, size = 200, prob=p)
p <- seq(from = 0, to = 1, length.out = 1000)
prior <- rep(1, length(p))
likelihood <- dbinom(111, size = 200, prob=p)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
plot(posterior ~ p, type = "l")
p[which.max(posterior)]
p.samples <- sample(p, size = 10000, replace = TRUE, prob = posterior)
HPDI(p.samples, prob=0.89)
HPDI(p.samples, prob=0.50)
HPDI(p.samples, prob=0.97)
bsim <- rbinom(10000, size=200, prob=p.samples)
dens(bsim, adj=0.1)
b1sim <- rbinom(10000, size = 100, prob = p.samples)
dens(b1sim, adj = 0.1)
abline(v=sum(birth1), col = "red")
birth2[birth1 == 0]
b01 <- birth2[birth1 == 0]
b01sim <- rbinom(10000, size = length(b01), prob = p.samples)
dens(b01sim, adj = 0.1)
abline(v=sum(b01), col = "red")
sample_mu <- rnorm(1e4, 0, 10)
sample_sigma <- rexp(1e4, rate = 1)
prior_y <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_y)
data(Howell1); d <- Howell1; d2 <- d[ d$age >= 18 , ]
m4.3 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*(weight) ,
a ~ dnorm( 178 , 20 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
m4.3a <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - xbar ) ,
a ~ dnorm( 178 , 20 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
# define the average weight, x-bar
xbar <- mean(d2$weight)
m4.3a <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - xbar ) ,
a ~ dnorm( 178 , 20 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
precis(m4.3)
precis(m4.3a)
pairs(m4.3)
pairs(m4.3a)
plot(height ~ weight, data=d2, col=rangi2)
post <- extract.samples(m4.3a)
post2 <- extract.samples(m4.3)
a_map <- mean(post$a)
b_map <- mean(post$b)
a2_map <- mean(post2$a)
b2_map <- mean(post2$b)
curve(a_map + b_map*(x-xbar), add = TRUE)
curve(a_map + b_map*(x), add = TRUE)
curve(a2_map + b2_map(x - xbar), add = TRUE)
b2_map <- mean(post2$b)
curve(a2_map + b2_map(x - xbar), add = TRUE)
curve(a2_map + b2_map*(x - xbar), add = TRUE)
curve(a_map + b_map*(x), add = TRUE)
#4M8
data("cherry_blossoms")
d <- cherry_blossoms
precis(d)
d2 <- d[complete.cases(d$doy),]
num_knots <- 25
knot_list <- quantile(d2$year, probs=seq(0,1, length.out = num_knots))
library(splines)
B <- bs(d2$year,
knots = knot_list[-c(1,num_knots)],
degree = 3, intercept = TRUE)
plot(NULL, xlim=range(d2$year), ylim=c(0,1), xlab="year", ylab="basis")
for (i in 1:ncol(B)) lines(d2$year, B[,1]
## R code 4.75
plot( NULL , xlim=range(d2$year) , ylim=c(0,1) , xlab="year" , ylab="basis" )
## R code 4.75
plot( NULL , xlim=range(d2$year) , ylim=c(0,1) , xlab="year" , ylab="basis" )
for ( i in 1:ncol(B) ) lines( d2$year , B[,i] )
## Knot number and prior weights control
## R code 4.76
m4.7 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(100,10),
w ~ dnorm(0,10),
sigma ~ dexp(1)
), data=list( D=d2$doy , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
## R code 4.77
post <- extract.samples( m4.7 )
w <- apply( post$w , 2 , mean )
plot( NULL , xlim=range(d2$year) , ylim=c(-6,6) ,
xlab="year" , ylab="basis * weight" )
for ( i in 1:ncol(B) ) lines( d2$year , w[i]*B[,i] )
## R code 4.76
m4.7 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(100,10),
w ~ dnorm(0,20),
sigma ~ dexp(1)
), data=list( D=d2$doy , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
## R code 4.77
post <- extract.samples( m4.7 )
w <- apply( post$w , 2 , mean )
plot( NULL , xlim=range(d2$year) , ylim=c(-6,6) ,
xlab="year" , ylab="basis * weight" )
for ( i in 1:ncol(B) ) lines( d2$year , w[i]*B[,i] )
p <- c(0.3, 0.7)
-sum(p*log(p))
p2 <- c(0.20, 0.25, 0.25, 0.30)
-sum(p2*log(p2))
p3 <- c(1/3, 1/3, 1/3)
-sum(p3*log(p3))
WAIC(m4.3)
m4.3a <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - xbar ) ,
a ~ dnorm( 178 , 10 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
m4.3a <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - xbar ) ,
a ~ dnorm( 178 , 10 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
data(Howell1); d <- Howell1; d2 <- d[ d$age >= 18 , ]
# define the average weight, x-bar
xbar <- mean(d2$weight)
m4.3 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*(weight) ,
a ~ dnorm( 178 , 20 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
m4.3a <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + b*( weight - xbar ) ,
a ~ dnorm( 178 , 10 ) ,
b ~ dlnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d2 )
WAIC(m4.3)
WAIC(m4.3a)
d <- data("Laffer")
data("Laffer")
d <- Laffer
View(d)
lm1 <- (tax_revenue ~ tax_rate^2, data = d)
lm1 <- lm(tax_revenue ~ tax_rate^2, data = d)
ggplot(data = d, aes(x = tax_rate, y = tax_revenue)) +
geom_point(size = 2) + geom_smooth(method = "lm")
ggplot(data = d, aes(x = tax_rate, y = tax_revenue)) +
geom_point(size = 2) + geom_smooth(lm1)
ggplot(data = d, aes(x = tax_rate, y = tax_revenue)) +
geom_point(size = 2) + geom_smooth(method = NULL, formula = lm1)
ggplot(data = d, aes(x = tax_rate, y = tax_revenue)) +
geom_point(size = 2) + geom_smooth(method = NULL, formula = y ~ x^2)
View(Laffer)
#9M1
# Estimate the ruggedness model with a uniform prior
rm(list =ls())
data("rugged")
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[ complete.cases(d$rgdppc_2000) , ]
dd$log_gdp_std <- dd$log_gdp / mean(dd$log_gdp)
dd$rugged_std <- dd$rugged / max(dd$rugged)
dd$cid <- ifelse( dd$cont_africa==1 , 1 , 2 )
## R code 9.13
dat_slim <- list(
log_gdp_std = dd$log_gdp_std,
rugged_std = dd$rugged_std,
cid = as.integer( dd$cid )
)
str(dat_slim)
## R code 9.14
m9.1 <- ulam(
alist(
log_gdp_std ~ dnorm( mu , sigma ) ,
mu <- a[cid] + b[cid]*( rugged_std - 0.215 ) ,
a[cid] ~ dnorm( 1 , 0.1 ) ,
b[cid] ~ dnorm( 0 , 0.3 ) ,
sigma ~ dexp( 1 )
) , data=dat_slim , chains=1 )
## R code 9.14
m9.1 <- ulam(
alist(
log_gdp_std ~ dnorm( mu , sigma ) ,
mu <- a[cid] + b[cid]*( rugged_std - 0.215 ) ,
a[cid] ~ dnorm( 1 , 0.1 ) ,
b[cid] ~ dnorm( 0 , 0.3 ) ,
sigma ~ dexp( 1 )
) , data=dat_slim , chains=1 )
rm(list = ls())
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES.rda")
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES")
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES.rds")
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES.Rdata")
load("MA thesis/Reed-Smith-JHRED-CANDIDATES.Rdata")
View(x)
x$name_jp[1]
JPMMM <- x %>%
filter(year = "1994" | "1995")
library(tidyverse)
JPMMM <- x %>%
filter(year = "1994" | "1995")
JPMMM <- x %>%
filter(year == "1994" | "1995")
JPMMM <- x %>%
filter(year == 1994 | 1995)
JPMMM <- x %>%
filter(year == 1994)
JPMMM <- x %>%
filter(year == 1993)
View(JPMMM)
JPMMM <- x %>%
filter(year >= 1993)
View(JPMMM)
table(JPMMM$ken)
JPMMM <- x %>%
filter(year > 1993)
View(JPMMM)
View(JPMMM)
?lm
lag(JPMMM, k=1, yr, name="previous")
lag(JPMMM, k=1, JPMMM$yr, name="previous")
JPMMM96 <- JPMMM %>%
filter(yr == 19.0)
JPMMM00 <- JPMMM %>%
filter(yr == 20.0)
JPMMM02 <- JPMMM %>%
filter(yr == 21.0)
JPMMM05 <- JPMMM %>%
filter(yr == 22.0)
JPMMM09 <- JPMMM %>%
filter(yr == 23.0)
JPMMM12 <- JPMMM %>%
filter(yr == 24.0)
JPMMM14 <- JPMMM %>%
filter(yr == 25.0)
mean(JPMMM[which(ken = "NA")]$female)
mean(JPMMM[which(JPMMM$ken = "NA")]$female)
mean(JPMMM[which(JPMMM$ken == "NA")]$female)
mean(JPMMM[which(ken == "NA")]$female)
mean(JPMMM[(which(ken == "NA"))]$female)
mean(JPMMM96[which(ken == "NA")]$female)
mean(JPMMM96[which(JPMMM96$ken == "NA")]$female)
which(JPMMM96$ken == "NA")
mean(JPMMM96$female[which(JPMMM96$ken == "NA")])
View(JPMMM96)
JPMMM96$female[364,]
JPMMM96$female[, 364]
JPMMM96$female[364]
JPMMM96$female[23]
JPMMM96$female[24]
JPMMM96$female[22]
?$
$?
mean(JPMMM96$female[which(JPMMM96$ken == "NA")])
mean(JPMMM00$female[which(JPMMM00$ken == "NA")])
mean(JPMMM02$female[which(JPMMM02$ken == "NA")])
mean(JPMMM05$female[which(JPMMM05$ken == "NA")])
mean(JPMMM09$female[which(JPMMM09$ken == "NA")])
mean(JPMMM12$female[which(JPMMM12$ken == "NA")])
mean(JPMMM14$female[which(JPMMM14$ken == "NA")])
mean(JPMMM96$female[which(JPMMM96$prcode > 0)])
mean(JPMMM00$female[which(JPMMM00$prcode > 0)])
mean(JPMMM02$female[which(JPMMM02$prcode > 0)])
mean(JPMMM05$female[which(JPMMM05$prcode > 0)])
mean(JPMMM09$female[which(JPMMM09$prcode > 0)])
mean(JPMMM12$female[which(JPMMM12$prcode > 0)])
mean(JPMMM14$female[which(JPMMM14$prcode > 0)])
load("C:/Users/gardi/OneDrive/Documents/Research for Japanese Politics/clea_lc_20201216.rdata")
View(x)
View(clea_lc_20201216)
rm(list = ls())
SKLegData <-
readRDS("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
SKLegData <-
read.csv("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
load("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
library(haven)
X20160725_1320Ranked <- read_dta("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
View(X20160725_1320Ranked)
X20160725_1320Ranked$sex[1]
load("MA thesis/Reed-Smith-JHRED-CANDIDATES.Rdata")
View(x)
View(rugged)
View(dd)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
#mean() gir oss gjennomsnittet av et objekt, brukes som regel på enkelt variabler
#spesifisert med dollartegnet
mean(Dataeksempel$kjonn)
#mean() gir oss gjennomsnittet av et objekt, brukes som regel på enkelt variabler
#spesifisert med dollartegnet
mean(Dataeksempel$kjonn)
?tibble
library(tidyverse)
install.packages("plotly")
install.packages("tidyverse")
install.packages("rlang")
install.packages("rlang")
install.packages("readxl")
install.packages("tidyverse")
install.packages("rlang")
install.packages("rlang")
install.packages("tidyverse")
library(tidyverse)
library(plotly)
remove.packages(c("StanHeaders", "rstan"))
Sys.getenv("BINPREF")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Sys.which("make")
library(plotly)
library(tidyverse)
View(d)
ggplot(d, aes(x = rugged, y = desert)) +
geom_point()
library(plotly)
library(tidyverse)
ggplot(d, aes(x = rugged, y = desert)) +
geom_point()
Sys.which("make")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars.win")
if (!file.exists(M)) file.create(M)
cat("\n CXX14FLAGS += -mtune=native -O3 -mmmx -msse -msse2 -msse3 -mssse3 -msse4.1 -msse4.2",
file = M, sep = "\n", append = FALSE)
# only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
devtools::install_github("rmcelreath/rethinking")
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
install.packages("rlang")
install.packages("rlang")
update.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
View(d)
ggplot(d, aes(x = desert, y = rugged)) +
geom_point()
library(tidyverse)
install.packages("extrafont")
library(extrafont)
font_import(pattern = "lmroman*")
font_import(pattern = "lmroman*")
warnings()
setwd("~/STV1010 Seminarer/H22/Ressurser/Presentationslides/STV1010H22SeminarLederRessurser/FørsteGang")
getwd()
Sys.setlocale(category = "LC_ALL", "")
setwd("~/STV1010 Seminarer/H22/Ressurser/Presentationslides/STV1010H22SeminarLederRessurser/FørsteGang")
Sys.setlocale(category = "LC_ALL", "")
- Har dere noen flere spørsmål rundt det vi har snakket om?
?knitr::include_graphics
Sys.setlocale(category = "LC_ALL", "")
Sys.setlocale(category = "LC_ALL", "")
Sys.setlocale(category = "LC_ALL", "")
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
tinytex::tlmgr_update()
tinytex::reinstall_tinytex()
tinytex::reinstall_tinytex()
